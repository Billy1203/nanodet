#Config File example
save_dir: workspace/test1
model:

  ########### ShuffleNetV2 ############
#  arch:
#    name: GFL
#    backbone:
#      name: ShuffleNetV2
#      model_size: 1.0x
#      out_stages: [2,3,4]
#      activation: LeakyReLU
#    fpn:
#      name: PAN
#      in_channels: [116, 232, 464]
#      out_channels: 96
#      start_level: 0
#      num_outs: 3
  #####################################

  ########### MobileNetV2 ############
#  arch:
#    name: GFL
#    backbone:
#      name: MobileNetV2
#      out_stages: [2,4,6]
#    fpn:
#      name: TAN
#      in_channels: [32, 96, 1280]
#      out_channels: 96
#      start_level: 0
#      num_outs: 3
  #####################################

  ########### MobileNetV3 ############
  arch:
    name: GFL
    backbone:
      name: MobileNetV3
      out_stages: [2,6]
    fpn:
      name: PAN
      in_channels: [24, 48, 576]
      out_channels: 96
      start_level: 0
      num_outs: 3
  #####################################

    head:
      name: NanoDetHead
      num_classes: 4 #Please fill in the number of categories (not include background category)
      input_channel: 96
      feat_channels: 96
      stacked_convs: 2
      share_cls_reg: True
      octave_base_scale: 5
      scales_per_octave: 1
      strides: [8, 16, 32]
      reg_max: 7
      norm_cfg:
        type: BN
      loss:
        loss_qfl:
          name: QualityFocalLoss
          use_sigmoid: True
          beta: 2.0
          loss_weight: 1.0
        loss_dfl:
          name: DistributionFocalLoss
          loss_weight: 0.25
        loss_bbox:
          name: GIoULoss
          loss_weight: 2.0

class_names: &class_names ['hand', 'good', 'yeah', 'okay']  #Please fill in the category names (not include background category)
data:
  train:
    name: xml_dataset
    class_names: *class_names
    img_path: /home/yiheng/handPoseDataset/training_dataset/images  #Please fill in train image path
    ann_path: /home/yiheng/handPoseDataset/training_dataset/labels  #Please fill in train xml path
    input_size: [320,320] #[w,h]
    keep_ratio: True
    pipeline:
      perspective: 0.0
      scale: [0.6, 1.4]
      stretch: [[1, 1], [1, 1]]
      rotation: 0
      shear: 0
      translate: 0.2
      flip: 0.5
      brightness: 0.2
      contrast: [0.8, 1.2]
      saturation: [0.8, 1.2]
      normalize: [[103.53, 116.28, 123.675], [57.375, 57.12, 58.395]]
  val:
    name: xml_dataset
    class_names: *class_names
    img_path: /home/yiheng/handPoseDataset/validation_dataset/images #Please fill in val image path
    ann_path: /home/yiheng/handPoseDataset/validation_dataset/labels #Please fill in val xml path
    input_size: [320,320] #[w,h]
    keep_ratio: True
    pipeline:
      normalize: [[103.53, 116.28, 123.675], [57.375, 57.12, 58.395]]
device:
  gpu_ids: [1]
  workers_per_gpu: 12
  batchsize_per_gpu: 40
schedule:
#  resume:
#  load_model: YOUR_MODEL_PATH
  optimizer:
    name: SGD
    lr: 0.14
    momentum: 0.9
    weight_decay: 0.0001
  warmup:
    name: linear
    steps: 300
    ratio: 0.1
  total_epochs: 150
  lr_schedule:
    name: MultiStepLR
    milestones: [130,160,175,185]
    gamma: 0.1
  val_intervals: 10
evaluator:
  name: CocoDetectionEvaluator
  save_key: mAP

log:
  interval: 10
